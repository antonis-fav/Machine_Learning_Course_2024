# -*- coding: utf-8 -*-
"""problem1  (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19c-X1JLyyuRJMWzuwA8rPYWxQ5S0nQLS

## Εργασία 1 ##

Καλωσήρθατε στην πρώτη σας εργασία. Η εργασία αυτή έχει σκοπό να σας βοηθήσει να εμπεδώσετε τα γραμμικά μοντέλα.

Τα Jupyter Notebooks είναι αλληλεπιδραστικά περιβάλλοντα προγραμματισμού ενσωματωμένα σε μια ιστοσελίδα. Στο μάθημα "Μηχανική Μάθηση" τα χρησιμοποιούμε στο πρακτικό μέρος του μαθήματος.

Στην εργασία αυτή θα πρέπει να συμπληρώσετε κώδικα Python 3 στα σημεία που αναφέρουν # YOUR CODE HERE. Μην τροποποιείτε τον κώδικα που βρίσκεται εκτός αυτών των περιοχών.

Πρωτού παραδόσετε την εργασία σας σιγουρευτείτε ότι ο κώδικας σε όλα τα κελιά τρέχει σωστά. Για το σκοπό αυτό επιλέξτε από το μενού **Χρόνος εκτέλεσης (runtime) -> Επανεκίνηση περιόδου λειτουργίας και εκτέλεση όλων**.

Συμπληρώστε το όνομα (**NAME**) και το **AEM** σας παρακάτω:
"""

NAME = "Enter your Name here"
AEM = "Enter your AEM here"

"""---
## Μέρος A: NumPy (1 μονάδα)

Η βιβλιοθήκη [**NumPy**](https://numpy.org/) είναι η βασική βιβιλιοθήκη για επιστημονικούς υπολογισμούς σε Python. Παρέχει ένα υψηλής επίδοσης αντικείμενο για την αποθήκευση πολυδιάστατων πινάκων και εργαλεία για επεξεργασίας αυτών των πινάκων.

Μπορείτε να συμβουλεύεστε την τεκμηρίωση ([NumPy Doc](https://numpy.org/doc/1.18/user/quickstart.html)) αυτών των βιβλιοθηκών κατά την εκπόνηση της εργασίας.

Κατά σύμβαση πάντα φορτώνουμε τη βιβλιοθήκη με τον ακόλουθο τρόπο:
"""

# Run this cell
import numpy as np

"""**A1**: Ορίστε συνάρτηση που επιστρέφει πίνακα 2 διδαστάσεων με r γραμμές και c στήλες και περιέχει τυχαίες τιμές από 0 έως 1 με τη βοήθεια της συνάρτησης np.random.rand. Ακολουθούν τεστ ορθής λειτουργίας της συνάρτησης."""

def random_2d_array(r, c):
    """Επιστρέφει διδιάστατο πίνακα με r γραμμές και c στήλες.

    """
    # YOUR CODE HERE
    array = np.random.rand(r, c)
    print(array)
    return array
    raise NotImplementedError()

"""Τεστ επιστροφής πίνακα με τις σωστές διαστάσεις"""
assert np.shape(random_2d_array(3, 5)) == (3, 5)
assert np.shape(random_2d_array(5, 2)) == (5, 2)

"""**A2**: Ορίστε συνάρτηση που δέχεται δύο διδιάστατους πίνακες και επιστρέφει το γινόμενο του ανάστροφου του 1ου πίνακα με τον 2ο πίνακα με τη χρήση της numpy. Ακολουθούν τεστ ορθής λειτουργίας της συνάρτησης."""

def multiply_transpose(a, b):
    """Επιστρέφει το γινόμενο του ανάστροφου του 1ου πίνακα με τον 2ο πίνακα.

    """
    # YOUR CODE HERE
    a_inv = a.T
    mult_res = np.dot(a_inv, b)
    return(mult_res)

    raise NotImplementedError()

"""Τεστ επιστροφής πίνακα με τις σωστές διαστάσεις"""
a = random_2d_array(3, 5)
b = random_2d_array(3, 2)
assert np.shape(multiply_transpose(a, b)) == (5, 2)
assert np.shape(multiply_transpose(b, a)) == (2, 5)

"""## Μέρος Β: Γραμμικά μοντέλα (6 μονάδες) ##

Σε αυτό το μέρος της άσκησης θα χτίσουμε ένα μοντέλο γραμμικής παλινδρόμησης από το μηδέν.

**B1:** Υλοποιήστε τη σιγμοειδή συνάρτηση $\sigma(z)= \dfrac{1}{1 + exp(-z)}$ με τη NumPy. Ακολουθούν τεστ ορθής λειτουργίας της συνάρτησης.
"""

def sigmoid(z):
    """Υπολογίζει τη σιγμοειδή συνάρτηση."""
    # YOUR CODE HERE
    import math
    sigma = 1 / (1 + np.exp(-z))
    return(sigma)
    raise NotImplementedError()

"""Τεστ ορθού υπολογισμού σιγμοειδούς."""
assert sigmoid(0) == 0.5
assert np.round(sigmoid(7),8) == 0.99908895
assert np.round(sigmoid(-1),8) == 0.26894142

"""**B2:** Υλοποιήστε κλάση για τον αλγόριθμο της λογιστικής παλινδρόμησης. Αρχικοποιήστε τις παραμέτρους σε μηδενικές τιμές. Αποθηκεύστε τες στο διάνυσμα στήλη theta. Η συνάρτηση fit πρέπει να δέχεται πίνακα X με τις τιμές των μεταβλητών εισόδου και διάνυσμα στήλη y με τις τιμές της μεταβλητής εξόδου. Η συνάρτηση predict πρέπει να δέχεται πίνακα Χ με τις τιμές των μεταβλητών εισόδου. Ακολουθούν τεστ ορθής λειτουργίας των συναρτήσεων."""

class MyLogisticRegression:
    def __init__(self, num_iterations=2000, learning_rate=0.004):
      self.theta = None
      self.num_iterations = num_iterations
      self.learning_rate = learning_rate

    def fit(self, X, y):
        # YOUR CODE HERE

        print(X.shape)
        X = np.concatenate((np.ones((X.shape[0],1)), X), axis=1) #here the arguments for np.ones() are the number of rows equal to
                                                                        # data points = X.shape[0] and columns equal to 1. We do this to add the x0 parameter
        y = np.array(y).reshape(-1,1) #vectorize the target variable into a column vector

        n = X.shape[1] - 1
        print("N is equal to:{} \n".format(n))

        self.theta = np.zeros((n+1, 1))
        print(self.theta.shape)

        for _ in range(self.num_iterations):
            self.theta = self.theta - self.learning_rate*(1/X.shape[0])*(X.T @ (sigmoid(X @ self.theta) - y))


        cost = -(1/X.shape[0])*np.sum(y*(np.log(sigmoid(X @ self.theta)))+(1-y)*(np.log(1-sigmoid(X @ self.theta))))
        print(cost)

        print(self.theta)
        print(self.theta.shape)

        return(self.theta)
        raise NotImplementedError()

    def predict(self, X):
        # YOUR CODE HERE

        print("X shape is {}\n" .format(X.shape))
        X = np.concatenate((np.ones((X.shape[0],1)), X), axis=1)
        print("X shape is {}\n" .format(X.shape))

        y = np.zeros((X.shape[0]))

        print("y shape is {}\n". format(y.shape))


        for i in range(0, X.shape[0]):

          # Every row of X has dimensions (1, 4) in order to multiply this with Theta Transpose which has dimensions (1, 4)
          # we must reshape every row of X with dimensions  (4, 1), multiplication of (1, 4) @ (4, 1) will give a result with dimensions (1, 1)
          temp = np.array(X[i,:]).reshape(-1,1)

          print("temp shape is {}\n" .format(temp.shape))
          print("self.theta shape is {}\n" .format(self.theta.shape))
          print("self.theta inverse shape is {}\n" .format(self.theta.T.shape))

          prob = self.theta.T @ temp
          print("prob shape is {}\n" .format(prob.shape))

          print("Prob is {}\n".format(prob))
          if(prob >=0):
            y[i] = 1
          else:
            y[i] = 0
          print(y[i])

        print("y whole vector {} \n". format(y))

        #reshaping y into a column vector for the given testing purposes
        tmp = np.array(y).reshape(-1,1)
        y = tmp

        print("end")
        return(y)
        raise NotImplementedError()

"""Τεστ ορθής λειτουργίας fit"""
from sklearn.datasets import make_blobs

# δημιουργία δύο ομάδων από τυχαία σημεία με κέντρο 0,0,0 και 3,3,3 και τυπική απόκλιση 1
centers = [[0.0, 0.0, 0.0], [3.0, 3.0, 3.0]]
X, y = make_blobs(n_samples=200, centers=centers,
                  random_state=47, shuffle=False)
y = np.array(y).reshape(-1,1)

lr = MyLogisticRegression()
lr.fit(X, y)

assert np.allclose(lr.theta, np.array([[-1.1772064],[0.5026043],[0.40811666],[0.55685573]]))

"""Τεστ ορθής λειτουργίας predict"""
from sklearn.datasets import make_blobs

# δημιουργία δύο ομάδων από τυχαία σημεία με κέντρο 0,0,0 και 3,3,3 και τυπική απόκλιση 1
centers = [[0.0, 0.0, 0.0], [3.0, 3.0, 3.0]]
X, y = make_blobs(n_samples=200, centers=centers,
                  random_state=47, shuffle=False)
y = np.array(y).reshape(-1,1)

lr = MyLogisticRegression()
lr.fit(X, y)

assert np.allclose(lr.predict(X[[0,199],:]), np.array([[0],[1]]))

"""## Μέρος Γ: Ομαλοποίηση (3 μονάδες)

**Γ1:** Υλοποιήστε κλάση για τον αλγόριθμο της λογιστικής παλινδρόμησης που να υποστηρίζει και ομαλοποίηση L1 και L2. Αρχικοποιήστε τις παραμέτρους σε μηδενικές τιμές. Αποθηκεύστε τες στο διάνυσμα στήλη theta. Η συνάρτηση fit πρέπει να δέχεται πίνακα X με τις τιμές των μεταβλητών εισόδου και διάνυσμα στήλη y με τις τιμές της μεταβλητής εξόδου. Ακολουθούν τεστ ορθής λειτουργίας.
"""

class MyLogisticRegression:
    def __init__(self, num_iterations=2000, learning_rate=0.004, penalty="None", l=10):
        self.theta = None
        self.num_iterations = num_iterations
        self.learning_rate = learning_rate
        self.penalty = penalty
        self.l = l

    def fit(self, X, y):
        # YOUR CODE HERE
        if(self.penalty == "L2"):
          a = self.l / (2 * X.shape[0])
        elif(self.penalty == "L1"):
          a = self.l / (X.shape[0])

        X = np.concatenate((np.ones((X.shape[0],1)), X), axis=1) #here the arguments for np.ones() are the number of rows equal to
                                                                # data points = X.shape[0] and columns equal to 1. We do this to add the x0 parameter
        y = np.array(y).reshape(-1,1) #vectorize the target variable into a column vector

        n = X.shape[1] - 1

        #in this case we dont calculate theta throught algebraic notations, as we need to include the parameter (L2 or L1) to penalize outlier values
        self.theta = np.zeros(n+1)
        for _ in range(self.num_iterations):
          theta_temp = self.theta.copy()
          update = np.zeros(n+1)
          for i in range(X.shape[0]):
              error = sigmoid(theta_temp.dot(X[i]))-y[i][0]

              if(self.penalty == "L2"):
                for j in range(n+1):
                  if(j == 0):
                    update[j] += error*X[i][j]
                  else:
                    update[j] += error*X[i][j] + (2 * a * self.theta[j])
              elif(self.penalty == "L1"):
                for j in range(n+1):
                  if(j == 0):
                    update[j] += error*X[i][j]
                  else:
                    update[j] += error*X[i][j]  + (a * (np.sign(self.theta[j])))
              else:
                for j in range(n+1):
                  update[j] += error*X[i][j]
          for j in range(n+1):
            self.theta[j] = self.theta[j] - self.learning_rate*(1/X.shape[0])*update[j]

        cost = 0
        for i in range(X.shape[0]):
          cost += -(1/X.shape[0])*(y[i][0]*(np.log(sigmoid(self.theta.dot(X[i]))))+(1-y[i][0])*(np.log(1-sigmoid(self.theta.dot(X[i])))))
        print(cost)

        print(self.theta)
        print(self.theta.shape)
        #necessary reshaping of self.theta into a column vector for testing purposes
        res = np.array(self.theta).reshape(-1,1)
        self.theta = res

        return(self.theta)
        raise NotImplementedError()

    def predict(self, X):
        # YOUR CODE HERE
        X = np.concatenate((np.ones((X.shape[0],1)), X), axis=1)

        y = np.zeros((X.shape[0]))

        for i in range(0, X.shape[0]):

          temp = np.array(X[i,:]).reshape(-1,1)

          prob = self.theta.T @ temp

          if(prob >=0):
            y[i] = 1
          else:
            y[i] = 0

        tmp = np.array(y).reshape(-1,1)
        y = tmp

        return(y)
        raise NotImplementedError()

"""Τεστ ορθής λειτουργίας fit L2"""
from sklearn.datasets import make_blobs

# δημιουργία δύο ομάδων από τυχαία σημεία με κέντρο 0,0,0 και 3,3,3 και τυπική απόκλιση 1
centers = [[0.0, 0.0, 0.0], [3.0, 3.0, 3.0]]
X, y = make_blobs(n_samples=200, centers=centers,
                  random_state=47, shuffle=False)
y = np.array(y).reshape(-1,1)

lr = MyLogisticRegression(penalty="L2", l=10)
lr.fit(X, y)
assert np.allclose(lr.theta, np.array([[-1.148294],[0.46202407],[0.38788976],[0.50990465]]))
lr = MyLogisticRegression(penalty="L2", l=100)
lr.fit(X, y)
assert np.allclose(lr.theta, np.array([[-0.95841014],[0.30961435],[0.29482345],[0.33574242]]))

"""Τεστ ορθής λειτουργίας fit L1"""
from sklearn.datasets import make_blobs

# δημιουργία δύο ομάδων από τυχαία σημεία με κέντρο 0,0,0 και 3,3,3 και τυπική απόκλιση 1
centers = [[0.0, 0.0, 0.0], [3.0, 3.0, 3.0]]
X, y = make_blobs(n_samples=200, centers=centers,
                  random_state=47, shuffle=False)
y = np.array(y).reshape(-1,1)

lr = MyLogisticRegression(penalty="L1", l=100)
lr.fit(X, y)
assert np.allclose(lr.theta, np.array([[-0.39128777],[0.07264989],[0.06445718],[0.2047192]]))
