# -*- coding: utf-8 -*-
"""problem2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11cCttxJLXrTatSN9Zyav-CaPYXrxKdOX

## Εργασία 2 ##

Καλωσήρθατε στην δεύτερη σας εργασία. Η εργασία αυτή έχει σκοπό να σας βοηθήσει να εμπεδώσετε τα δενδρικά μοντέλα και την αξιολόγηση μοντέλων.

Στην εργασία αυτή θα πρέπει να συμπληρώσετε κώδικα Python 3 στα σημεία που αναφέρουν # YOUR CODE HERE. Μην τροποποιείτε τον κώδικα που βρίσκεται εκτός αυτών των περιοχών.

Πρωτού παραδόσετε την εργασία σας σιγουρευτείτε ότι ο κώδικας σε όλα τα κελιά τρέχει σωστά. Για το σκοπό αυτό επιλέξτε από το μενού Χρόνος εκτέλεσης (runtime) -> Επανεκίνηση περιόδου λειτουργίας και εκτέλεση όλων.

Συμπληρώστε το όνομα (NAME) και το AEM σας παρακάτω:
"""

NAME = "Enter your Name here"
AEM = "Enter your AEM here"

"""**1** Διαβάστε το διαθέσιμο από την sklearn σύνολο δεδομένων diabetes που αφορά την πρόβλεψη της πορείας που θα έχει ένας ασθενής με διαβήτη ένα χρόνο μετά (εργασία παλινδρόμησης) και αποθηκεύστε το σε μια μεταβλητή με το όνομα diabetes. (0.5 μονάδες)"""

# YOUR CODE HERE
import pandas as pd
from sklearn.datasets import load_diabetes
diabetes = load_diabetes()

# print(diabetes.data)
# print(diabetes.target)
# print(diabetes.target.shape)
# print(diabetes.feature_names)
# raise NotImplementedError()

"""Τεστ ορθής ανάγνωσης του συνόλου δεδομένων"""
assert diabetes.feature_names == ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']

"""**2** Χωρίστε το σύνολο που διαβάσατε σε υποσύνολο ελέγχου 20% και υποσύνολο εκπαίδευσης 80% με την μέθοδο train_test_split και σπόρο τυχαιότητας 42. Aποθηκεύστε το σύνολο εκπαίδευσης σε μεταβλητές X_train, y_train και το σύνολο ελέγχου σε μεταβλητές X_test, y_test. (0.5 μονάδες)"""

# YOUR CODE HERE
from sklearn.model_selection  import train_test_split

X_train, X_test, y_train, y_test  = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=42)

# raise NotImplementedError()

"""Τεστ ορθού διαχωρισμού του συνόλου δεδομένων"""
assert round(X_train[0][8], 5) == 0.02736
assert round(X_test[0][8], 5) == 0.03243

"""**3** Χρησιμοποιώντας τα δεδομένα εκπαίδευσης, εκπαιδεύστε δύο δένδρα παλινδρόμησης με κριτήρια διαχωρισμού τα squared_eror και poisson ([δείτε ενότητα 1.10.7.2](https://scikit-learn.org/stable/modules/tree.html#tree)) αντίστοιχα, θέτοντας τον σπόρο τυχαιότητας στην τιμή 42 και το μέγιστο βάθος στην τιμή 3. Υπολογίστε τη μετρική r2 με βάση τις προβλέψεις τους στα δεδομένα ελέγχου, τις οποίες αποθηκεύστε στις μεταβλητές y_pred1 (squared_error) και y_pred2 (poisson) αντίστοιχα.
Αποθηκεύστε τις μετρικές στις μεταβλητές r2_squared_error και r2_poisson αντίστοιχα. (1 μονάδα)
"""

# YOUR CODE HERE
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error


tree_clf_sq = DecisionTreeRegressor(criterion='squared_error', max_depth=3, random_state=42)
tree_clf_poi = DecisionTreeRegressor(criterion='poisson', max_depth=3, random_state=42)

tree_clf_sq.fit(X_train, y_train)
tree_clf_poi.fit(X_train, y_train)

y_pred1 = tree_clf_sq.predict(X_test)
y_pred2 = tree_clf_poi.predict(X_test)

r2_squared_error = r2_score(y_test, y_pred1)
r2_poisson = r2_score(y_test, y_pred2)

# raise NotImplementedError()

"""Τεστ ορθού υπολογισμού των μετρικών"""
assert round(r2_squared_error, 3) == 0.329
assert round(r2_poisson, 3) == 0.391
assert len(y_pred1) == len(y_pred2)

"""**4** Αναπτύξτε κώδικα με βάση την ιδιότητα [tree_](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py) του παρακάτω μοντέλου, προκειμένου να εμφανίσετε το μονοπάτι που ακολουθήθηκε στο δένδρο για την πρόβλεψη της πρώτης περίπτωσης του συνόλου ελέγχου. Σε περίπτωση που ελέγχεται δεύτερη φορά μια μεταβλητή στο μονοπάτι, θα πρέπει να διατηρούμε τον τελευταίο και στενότερο περιορισμό. Ακολουθούν παραδείγματα ορθής λειτουργίας, στα οποία φαίνεται και η μορφή αν-τότε που πρέπει να έχει το μονοπάτι. (4 μονάδες)"""

from sklearn.tree import export_text
model = DecisionTreeRegressor(max_depth=3, random_state=42)
model.fit(X_train, y_train)

def get_path(tree, instance, feature_names):
# YOUR CODE HERE

  n_nodes = tree.tree_.node_count
  children_left = tree.tree_.children_left
  children_right = tree.tree_.children_right
  feature = tree.tree_.feature
  threshold = tree.tree_.threshold
  values = tree.tree_.value

  # array that contains all the nodes the instance travels through
  node_indicator = tree.decision_path(X_test)
  # array that contains the ids of all the leaf nodes of the tree
  leaf_id = tree.apply(X_test)

  #We find the index of the row inside X_test that corresponds to the given instance
  k = X_test[:,] == instance

  instance_found = 0
  #the row(s) of k which elements are all equal to 1, corresponds  to the given instance
  for i in range(0, X_test.shape[0], 1):
   if all(k[i]):
    index = i
    instance_found = 1

  if (instance_found == 0):
    print("Didn't found the instance exiting...\n")
    return(1)

  #predic the X_test
  y_pred = tree.predict(X_test)

  str_result = []
  str_result.clear()
  str_result.append("αν")


  sample_id = index
  node_index = node_indicator.indices[
    node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]
  ]

  for node_id in node_index:

    # Reached a leaf node, add the predicted value of the sample to the final string
    if leaf_id[sample_id] == node_id:
      str_result.append("τότε" + " " + str(round(y_pred[index],2)))
      continue

    # check if value of the split feature for the sample is below threshold
    if X_test[sample_id, feature[node_id]] <= threshold[node_id]:
        threshold_sign = "<="
    else:
        threshold_sign = ">"

    #in the root node we just push the results into the final string
    if(node_id == 0):
      str_result.append(str(diabetes.feature_names[feature[node_id]]))
      str_result.append(str(threshold_sign))
      str_result.append(str(round(threshold[node_id],2)))

    #for every intermediate node we check if the node's feature have been examined before
    else:
      #if the node's feature have been examined before we might push results into the final string flag = 1 else we will surely push new results in the final string flag = 0
      flag = 0
      for i in str_result:

        if str(diabetes.feature_names[feature[node_id]]) == i:
          # Get the index of the element inside the final string that is equal to the current node's feature
          index_str = str_result.index(i)

          #We will mark the old feature threshold (str_result[index_str+2]) as A and the current node's feature threshold as B
          #We must examine 6 different cases

          #1st case where A, B <0 and the sign = "<="
          if (round(threshold[node_id],2) <= 0) & (float(str_result[index_str+2])<=0):
            if (threshold_sign == "<=") & (str_result[index_str+1]== "<="):
              if abs(round(threshold[node_id],2)) > abs(float(str_result[index_str+2])):
                flag = 1
                str_result[index_str+2] = str(round(threshold[node_id],2))
                continue
              else:
                continue
            # 2nd case where A, B < 0 and the sign = ">"
            elif (threshold_sign == ">") & (str_result[index_str+1] == ">"):
              if abs(round(threshold[node_id],2)) < abs(float(str_result[index_str+2])):
                flag = 1
                str_result[index_str+2] = str(round(threshold[node_id],2))
                continue
              else:
                continue
            else:
              continue

          elif (round(threshold[node_id],2) > 0) & (float(str_result[index_str+2]) > 0):
            # 3rd case where A,B >0 and the sign = "<="
            if (threshold_sign == "<=") & (str_result[index_str+1]== "<="):
              if round(threshold[node_id],2) < float(str_result[index_str+2]):
                flag = 1
                str_result[index_str+2] = str(round(threshold[node_id],2))
                continue
              else:
                continue
            # 4th case where A, B >0 and the sign = ">"
            elif(threshold_sign == ">") & (str_result[index_str+1]== ">"):
              if round(threshold[node_id],2) > float(str_result[index_str+2]):
                flag = 1
                str_result[index_str+2] = str(round(threshold[node_id],2))
                continue
              else:
                continue
            else:
              continue

          else:
            #5th case where A and B have different signs and the sign = "<="
            if(threshold_sign == "<="):
              if (round(threshold[node_id],2) <= 0):
                flag = 1
                str_result[index_str+2] = str(round(threshold[node_id],2))
              else:
                continue
            #6th case where A and B have different signs and the sign = ">"
            else:
              if (round(threshold[node_id],2) >= 0):
                flag = 1
                str_result[index_str+2] = str(round(threshold[node_id],2))
              else:
                continue

      if (flag == 0):
        str_result.append("και")
        str_result.append(str(diabetes.feature_names[feature[node_id]]))
        str_result.append(str(threshold_sign))
        str_result.append(str(round(threshold[node_id],2)))

    print(
        "decision node {node} : (X_test[{sample}, {feature}] = {value}) "
        "{inequality} {threshold})".format(
            node=node_id,
            sample=sample_id,
            feature=feature[node_id],
            value=X_test[sample_id, feature[node_id]],
            inequality= threshold_sign,
            threshold= round(threshold[node_id],2),
        )

    )

  # concatenating the result list in order to reach the desired output form of the testing methods
  str_result = " ".join(str_result)
  print(str_result)
  return(str_result)

  raise NotImplementedError()

"""Τεστ ορθού υπολογισμού του μονοπατιού"""
assert get_path(model, X_test[0], diabetes.feature_names) == 'αν bmi <= 0.01 και s5 > 0.01 και s4 <= 0.09 τότε 159.57'
assert get_path(model, X_test[1], diabetes.feature_names) == 'αν bmi > 0.01 και bmi <= 0.07 και s6 <= 0.03 τότε 175.8'
assert get_path(model, X_test[6], diabetes.feature_names) == 'αν bmi > 0.07 και s2 > 0.02 τότε 225.75'

"""**5** Διαχωρίστε τα δεδομένα diabetes σε υποσύνολα εκπαίδευσης 60% (X_train, y_train), επικύρωσης 15% (X_val, y_val) και ελέγχου 25% (X_test, y_test) με σπόρο τυχαιότητας 42. (1 μονάδα)"""

# YOUR CODE HERE

diabetes = load_diabetes()
X_train = diabetes.data
y_train = diabetes.target

X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.25, random_state=42) # testing set -> 25% of the initial overall training set
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # 0.2 x 0.75 (remaining training set) = 0.15 -> validation set equal to 15% of the initial training set
# raise NotImplementedError()

"""Τεστ ορθού διαχωρισμού του συνόλου δεδομένων"""
assert round(X_train[0][8], 5) == -0.08024
assert round(X_val[0][8], 5) == 0.09924
assert round(X_test[0][8], 5) == 0.03243

"""**6** Υλοποιήστε συνάρτηση, η οποία δοθέντος ενός δενδρικού μοντέλου παλινδρόμησης, διερευνά όλες τις ακέραιες τιμές της μεταβλητής min_samples_leaf από ένα κάτω όριο μέχρι ένα άνω όριο και επιστρέφει την βέλτιστη με βάση το mean squared error στο παραπάνω σύνολο επικύρωσης έπειτα από εκπαίδευση στο παραπάνω σύνολο εκπαίδευσης. Επιπλέον επιστρέφει και το mean squared error (στρογγυλοποιημένο σε ακέραιο) που πετυχαίνει στο σύνολο ελέγχου το μοντέλο με την βέλτιστη επίδοση στο σύνολο επικύρωσης. (2 μονάδες)"""

from sklearn.metrics import mean_squared_error

def best_min_samples_leaf(model, min, max):
# YOUR CODE HERE

  import sys

  #Declaring a variable with the maximum integer value
  min_error = sys.maxsize
  best_min_samples_leaf = 0
  mse = 0

  #max+1 as the upper bound is exclusive
  for i in range(min, max+1):
    min_samples_leaf = {"min_samples_leaf":i}
    #modifying the parameters of the DecisionTreeRegressor
    model.set_params(**min_samples_leaf)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_val)
    mse = (mean_squared_error(y_pred, y_val))
    print(mse)

    if mse < min_error:
      min_error = mse
      best_min_samples_leaf = i

  ### More elegant solution but the use of the built in function min() is blocked by the local declaration of the variable min which is an input in the function
  # min_error = min(mse)
  # best_min_samples_leaf = mse.index(min_error) + 1

  min_samples_leaf = {"min_samples_leaf": best_min_samples_leaf}
  model.set_params(**min_samples_leaf)
  model.fit(X_train, y_train)

  y_test_pred = model.predict(X_test)
  mse_test = mean_squared_error(y_test_pred, y_test)


  print(best_min_samples_leaf, round(mse_test))

  return(best_min_samples_leaf, round(mse_test))
# raise NotImplementedError()

"""Τεστ ορθής υλοποίησης συνάρτησης"""
model = DecisionTreeRegressor(max_depth=3, random_state=42)
assert best_min_samples_leaf(model, 1, 8) == (7, 3358)
assert best_min_samples_leaf(model, 5, 15) == (11, 3271)

"""**7** Υλοποιήστε συνάρτηση η οποία δοθέντος ενός μοντέλου παλινδρόμησης, ενός συνόλου δεδομένων και μίας μετρικής, το αξιολογεί με τη μέθοδο της σταυρωτής επικύρωσης "άφησε ένα εκτός". (1 μονάδα)"""

from sklearn.model_selection import LeaveOneOut
import numpy as np

def leave_one_out(model, X, y, metric):
# YOUR CODE HERE
  loo = LeaveOneOut()
  loo.get_n_splits(X)

  accuracies = []
  for train_index, test_index in loo.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracies.append(mean_squared_error(y_test, y_pred))

  avg = np.average(accuracies)
  print(round(avg))
  return(avg)
# raise NotImplementedError()

"""Τεστ ορθής υλοποίησης συνάρτησης"""
model = DecisionTreeRegressor(max_leaf_nodes=6, min_samples_leaf=2, random_state=42)
assert round(leave_one_out(model, diabetes.data, diabetes.target, mean_squared_error), 0) == 3354